{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb172d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Linear, Parameter, ReLU, GELU, SiLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c276fd0",
   "metadata": {},
   "source": [
    "## Standard MLP Block\n",
    "\n",
    "- basic up, down, and activation func\n",
    "- x is in shape (bs, seqlen, hidden_size)\n",
    "- use standard layer norm `((x-mean(x))/(var(x)+eps))*W +B`\n",
    "- standard mlp applies layer norm after mlp\n",
    "- skip connection before norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6582db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LayerNorm(Module):\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.weight = Parameter(torch.rand(hidden_size))\n",
    "        self.bias = Parameter(torch.rand(hidden_size))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_mean = torch.mean(x, dim=1).unsqueeze(1)\n",
    "        x_variance = torch.var(x + self.eps, dim=1).unsqueeze(1)\n",
    "        norm_x = (x - x_mean) / (x_variance + self.eps)\n",
    "        return self.weight * norm_x + self.bias\n",
    "        \n",
    "\n",
    "class StandardMLP(Module):\n",
    "    def __init__(self, hidden_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.up_proj = Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.down_proj = Linear(intermediate_size, hidden_size, bias=False)\n",
    "        self.act_fn = ReLU()\n",
    "        self.ln = LayerNorm(hidden_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        up = self.act_fn(self.up_proj(x))\n",
    "        down = self.down_proj(up)\n",
    "        return self.ln(down + x) # residual connection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c276b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 32, 128)\n",
    "mlp = StandardMLP(128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74eb71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3871,  3.4959, -1.2076,  ..., -1.6955,  0.8514,  0.0924],\n",
       "         [ 0.1074,  1.6093, -0.3789,  ...,  3.3887,  0.7555,  0.5051],\n",
       "         [ 0.6063, -3.2555,  0.6370,  ..., -0.2145,  0.7132,  0.4433],\n",
       "         ...,\n",
       "         [ 0.5588, -1.0086, -0.5843,  ...,  2.7614,  0.6521,  0.6618],\n",
       "         [ 0.2326, -1.6392,  1.5063,  ..., -1.8309,  0.7629, -0.0828],\n",
       "         [ 0.2114,  2.4136, -1.5328,  ...,  0.3696,  0.7693,  0.3181]],\n",
       "\n",
       "        [[ 0.4951, -0.0211, -2.1303,  ...,  2.4653,  0.6135,  0.1638],\n",
       "         [ 0.6043, -1.3277,  0.0066,  ...,  4.1590,  0.6071, -0.1181],\n",
       "         [ 0.4841,  2.2919,  0.7837,  ..., -0.1330,  0.6588,  0.4361],\n",
       "         ...,\n",
       "         [ 0.3120, -3.3606,  2.1393,  ...,  0.6211,  0.5291, -0.0717],\n",
       "         [ 0.3507,  2.5743,  1.8553,  ...,  1.9771,  0.5814,  0.5648],\n",
       "         [ 0.5014,  0.6742,  1.2610,  ...,  4.3965,  0.6582,  0.0211]],\n",
       "\n",
       "        [[ 0.2781,  2.0835, -1.7272,  ...,  3.2816,  0.6353,  0.2760],\n",
       "         [ 0.1631,  2.9376, -1.9473,  ..., -1.4714,  0.6624,  0.0641],\n",
       "         [ 0.6151, -0.9632,  0.3613,  ..., -1.1484,  0.5810,  0.1161],\n",
       "         ...,\n",
       "         [ 0.3202,  0.1772, -0.1406,  ...,  2.1386,  0.6090,  0.1152],\n",
       "         [ 0.4630,  1.9974,  1.0572,  ..., -0.4597,  0.5627,  0.1814],\n",
       "         [ 0.4688, -0.3390,  1.7163,  ..., -0.2693,  0.7384,  0.3272]],\n",
       "\n",
       "        [[ 0.1652,  0.7201, -0.3413,  ...,  0.8081,  0.6463,  0.5051],\n",
       "         [ 0.2964,  2.5819, -0.4224,  ...,  3.8360,  0.7689,  0.4993],\n",
       "         [ 0.3283,  3.3010,  2.9606,  ..., -1.1858,  0.5919, -0.0337],\n",
       "         ...,\n",
       "         [ 0.6167, -1.7534,  0.6793,  ..., -1.4935,  0.7263, -0.0131],\n",
       "         [ 0.3782,  4.0557,  0.5818,  ..., -1.6394,  0.5842,  0.4829],\n",
       "         [ 0.5709, -2.1133,  1.6360,  ..., -2.2398,  0.5890,  0.0340]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cc8d6d",
   "metadata": {},
   "source": [
    "## GPT MLP Block\n",
    "\n",
    "- intermediate size is fixed (4 * hidden_size)\n",
    "- use GELU as act_fn\n",
    "- standard mlp applies layer norm before mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda59a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTMLP(StandardMLP):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__(hidden_size, 4 * hidden_size)\n",
    "        self.act_fn = GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        up = self.act_fn(self.up_proj(self.ln(x)))\n",
    "        down = self.down_proj(up)\n",
    "        return x + down\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb6b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 32, 128)\n",
    "mlp = GPTMLP(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb18ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed72fc",
   "metadata": {},
   "source": [
    "## LLaMa MLP Block\n",
    "\n",
    "- use RMSNorm (`x/(mean(x^2)+eps) * W`) instead of LN\n",
    "- use SiLU instead of GELU\n",
    "- smaller intermediate size than 4h\n",
    "- norm before mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd78467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(Module):\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.weight = Parameter(torch.rand(hidden_size))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rms_x = torch.mean(x ** 2, dim=1).unsqueeze(1)\n",
    "        return self.weight * x/(rms_x+self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff2017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLaMaMLP(Module):\n",
    "    def __init__(self, hidden_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.up_proj = Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.gate_proj = Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.down_proj = Linear(intermediate_size, hidden_size, bias=False)\n",
    "        self.rms_norm = RMSNorm(hidden_size)\n",
    "        self.act_fn = SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gated = self.act_fn(self.gate_proj(self.rms_norm(x)))\n",
    "        up = gated * self.up_proj(x)\n",
    "        down = self.down_proj(up)\n",
    "        return down + x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d968317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 32, 128)\n",
    "mlp = LLaMaMLP(128, 342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d57ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7474,  0.8281,  0.5100,  ...,  0.2617,  0.9431,  0.0669],\n",
       "         [ 0.7033,  0.3637,  0.8419,  ...,  0.2813,  0.1584,  0.3039],\n",
       "         [ 0.4184,  0.7633,  0.2466,  ...,  0.7423,  0.4674,  0.4228],\n",
       "         ...,\n",
       "         [ 0.5765,  0.8865,  0.5871,  ...,  0.6940,  0.5202,  0.9704],\n",
       "         [ 0.5382,  0.4332,  0.1566,  ...,  0.6802,  0.1593,  0.2337],\n",
       "         [ 0.6232,  0.0181,  0.4253,  ...,  0.6246,  0.7077,  0.6082]],\n",
       "\n",
       "        [[ 0.8238,  0.1485,  0.0760,  ...,  0.6720,  0.4226,  0.8507],\n",
       "         [-0.0671,  0.6248,  0.1084,  ...,  0.1321,  0.1907,  0.3431],\n",
       "         [ 0.1610,  0.3132,  0.4587,  ...,  0.6930,  0.8047,  0.2974],\n",
       "         ...,\n",
       "         [ 0.4569,  0.9068,  0.2996,  ...,  0.0283,  0.4840,  0.4164],\n",
       "         [ 0.4503,  0.0296,  0.7272,  ...,  0.6038,  0.6601,  0.7697],\n",
       "         [ 0.7394,  0.3530,  0.9824,  ...,  0.3131,  0.2823,  0.4291]],\n",
       "\n",
       "        [[ 0.5240,  0.7660,  0.7887,  ...,  0.7162,  0.0810,  0.3355],\n",
       "         [ 0.6720,  0.2293,  0.8425,  ...,  0.2146,  0.3605,  0.8250],\n",
       "         [ 0.2454,  0.7262,  0.1302,  ...,  0.0711,  0.7617,  0.0791],\n",
       "         ...,\n",
       "         [ 0.0353,  0.1637,  0.8490,  ...,  0.6211,  0.3417,  0.9039],\n",
       "         [-0.0349,  0.4661,  0.9874,  ...,  0.0249,  0.8659,  0.0947],\n",
       "         [ 0.6018,  0.1843,  0.8015,  ..., -0.0224,  0.7947,  0.5103]],\n",
       "\n",
       "        [[ 0.0966,  0.4643,  0.8639,  ...,  0.5850,  0.3032,  0.1866],\n",
       "         [ 0.8284,  0.6156,  0.8729,  ..., -0.0507,  0.9771, -0.0298],\n",
       "         [ 0.0451,  0.0484,  0.6271,  ..., -0.0603,  0.5694,  0.5628],\n",
       "         ...,\n",
       "         [ 0.3067,  0.3578,  0.0877,  ...,  0.2529,  0.1838,  0.7050],\n",
       "         [ 0.0394,  0.0598,  0.0084,  ..., -0.0647,  0.6513,  0.0891],\n",
       "         [-0.0164,  0.8384,  0.8111,  ...,  0.0533,  0.3543,  0.4670]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7463967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
